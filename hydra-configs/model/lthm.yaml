kind: "lthm"
type: "transformer_encoder"
name: "torch_lthm_model"
version: "v1"
sparse: False
log_q_config:
  num_buckets:  "${eval: 2 ** 24}"
  hash_offsets: [0, 34144, 7465477, 64363466, 4234551, 245435435, 143244556]
  alpha: 0.05
  p_init: 0.001
  beta: 0.0
context_width: 512
num_layers: 16
n_labels: 5
n_pcc_buckets: 15
max_pcc: 2.0
n_watch_duration_buckets: 20
max_watch_duration: 60.0
product_tower:
  inp_emb_dim: 32
  out_emb_dim: 512
  item_emb_dim: 128
  # disable blip LSH by setting blip vocab size to 1 and lsh_type to simhash
  cosine_lsh_config:
    - num_bins: 2
      num_proj: 32
    - num_bins: 4
      num_proj: 32
    - num_bins: 8
      num_proj: 32
    - num_bins: 12
      num_proj: 32
    - num_bins: 16
      num_proj: 32
    - num_bins: 20
      num_proj: 32
  detach_item_tower: True
  norm_threshold: 0.05
  norm_bins: 20
  model_init_metadata: ???
transformer_config:
  is_causal: True
  attn_config:
    attn_dropout: 0.0
    bias: False
    dropout: 0.0
    n_head: 32
    n_embd: 512
    attn_type: multi_query
    pos_bias:
      context_window: 513  # +1 for CLS
  is_sparse_attn: False
  enable_gradient_checkpointing: True
  #max_block_size: 1025
  #sparsity_factor: 0.75
  rotator_config:
    ff_mult: 4
loss_type: 'contrastive'
softmax_temperature: 0.05
lookahead: [0, 5, 6, 12, 24, 30]
lr: 1e-4
weight_decay: 1e-3
betas: [0.9, 0.95]
train_mini_batch_size: "${eval: 2 ** 5}"
min_history_size: 0
use_only_updated_data: False

features:
  defaults:
    numerical_features:
      embed_feature: False # TODO
    timestamp_features:
      emb_dim: 32
    bool_features:
      emb_dim: 32
    categorical_features:
      default_dtype: "int64" # this makes the default type of categorical features to be int64
      transform_value_to_lowercase: False
      embedding:
        num_embeddings: "${eval: 2 ** 34}"
        emb_dim: 32
        use_qr: True
      proj_dim: 0
    categorical_history_features:
      default_dtype: 'int64_list'



  tensor_list_features:
    - { name: labels, tower_name: other, shape: [768], source: {kind: input, dtype: "tensor_list"} }
    - { name: timestamps, tower_name: other, shape: [768], source: {kind: input, dtype: "tensor_list"} }

  categorical_history_features:
    - { name: product_ids, tower_name: other, history_length: 768, history_id_feature_name: product_id }

  extra_input_fields:
    - { name: customer_id, kind: categorical, do_not_convert_to_platform_type: True, source: { kind: input, dtype: "string" }, tower_name: other }